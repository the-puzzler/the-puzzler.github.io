<h1>Curriculum Is Key: Stepping Stones Toward AGI</h1>
<img src="posts/curriculum-is-key/images/opener.png" alt="Curriculum overview" style="display:block; margin:20px auto; max-width:100%; height:auto;">
<h2>Introduction</h2>


<h3>Aim</h3>
<p>
  Creativity under distribution shift is not a property you bolt onto an optimiser; it’s an emergent consequence of how capability is accumulated.
  The accumulation mechanism is curriculum. Specifically, curriculum that is generated by niche formation (local competition) and stabilised by diversity preservation.
  I’ll use <a href="https://arxiv.org/pdf/2003.08536" target="_blank" rel="noopener noreferrer">POET</a>, <a href="https://nbenko1.github.io/#/" target="_blank" rel="noopener noreferrer">Picbreeder</a>/<a href="https://arxiv.org/pdf/2505.11581" target="_blank" rel="noopener noreferrer">FERH</a>, and <a href="https://arxiv.org/pdf/2012.04322" target="_blank" rel="noopener noreferrer">MAP-Elites</a> as evidence that changing the reward landscape over time produces robust, perturbation-tolerant representations.
  Finally, I’ll argue that open-endedness points to a different target: population-level generality (aggregate intelligence) as a precursor to, or substitute for, single-agent AGI.
</p>

<h3>Definitions</h3>
<div class="def-table-wrap">
  <table class="def-table">
    <thead>
      <tr>
        <th>Term</th>
        <th>Definition</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Creativity</td>
        <td>The ability to generate useful novelty.</td>
      </tr>
      <tr>
        <td>Curriculum</td>
        <td>A sequence of training distributions.</td>
      </tr>
      <tr>
        <td>Robust internal representations</td>
        <td>Internal representations for which parameter changes lead to coherent variation instead of catastrophic failure.</td>
      </tr>
    </tbody>
  </table>
</div>

<hr>

<h2>Creativity</h2>
<img src="posts/curriculum-is-key/images/new-chall-new-behaviour-cycle.png" alt="New challenge to new behaviour cycle" style="display:block; margin:20px auto; max-width:100%; height:auto;">
<p>
  When facing challenges that are OOD with respect to our training data, we require creativity in order to surpass them. This intuition can be used to gather insight into the key components required to make creative agents. If a challenge is not part of our training distribution, we cannot rely on memory or learned tricks. Therefore, the only way for us to overcome this obstacle is if we can reliably mobilise internalised ideas about the world, reformulating them into a new configuration that can produce a behaviour we have never even witnessed. A concrete example is in how a child can approach a maths problem they have never encountered before. A child, not knowing their 9 times tables may be stumped at first. But if they know how to count, and they know how to decompose a product into a series of additions, they can solve it. Consider a neural network on the other hand. If it is never trained on the 9 times table, it will never be able to accurately predict the solutions to such problems. This example also highlights another facet of creativity: curriculum. Generalising to all times tables problems requires already knowing counting, and ideally addition, as quasi-discrete factorised concepts that can easily be re-combined and reapplied.
</p>

<p>
  The reason a model trained on all manner of multiplication except 9 times tables will struggle with exactly pinpointing the 9 times tables, is because it has been trained on the sole objective of maximising its fitness within the remit of a single thinly sliced objective. There is no incentive to build well factorised internal representations of the world. A well factorised internal representation may not be possible due to topological/architectural constraints. It may also not be possible to approximate based on the given task’s reward mechanism. Thus the only thing it can do is maximise its current reward, under its current distribution, which is fundamentally disabling.
</p>

<p>
  The aim of open-endedness as a field is to remedy this problem. Common solutions involve doing away with fixed objective training and instead, relying on open-ended curiosity and learnability as a guide. If one’s goal is to solve multiplication, it is impossible ahead of time to know that addition is useful. Knowing that would mean that one has already solved multiplication and as such can assign value to it. But if one does not optimise for an objective they want, then what is the point in optimising to begin with? The fundamental assumption of open-endedness is that if we can create systems of ever evolving capability there will be some solution found along the way that can be re-purposed for a task we might have. This is in spirit the same ethos behind natural evolution. One minute you are a bird flying high in the sky, the next minute you are a penguin. One minute you evolve big brains for complex social dynamics, the next minute, you describe quantum dynamics. The list goes on and on. The common thread is: new solvable challenge, reconfiguration of existing facets, new behaviour, gain new facets, repeat.
</p>

<hr>

<h2>Introduction to Open-Endedness</h2>
<p>
  Open-endedness is an emerging domain in the field of AI research. Open-endedness focuses on ideas surrounding robust internal representations, OOD performance and creativity. The main claim of open-endedness is that the necessary steps required to achieve an optimal solution are not known ahead of time and are very unlikely to be linear steps towards a fixed goal. The critical problem that open-endedness aims to solve is the discovery of these stepping stones.
</p>

<p>
  One way to conceptualise this idea is as an ‘unsupervised’ method for desparsification of reward signals. Going back to the human technology analogy, the right behaviour e.g. tinkering with magnets, is so unlikely for early humans that the behaviour will never occur, and so will never be rewarded. Hence, optimisation is practically random/blind. Another equivalent view is that of self-discovered curriculum. Instead of a human sitting and programming a set of sub-objectives/skills that are required to be learnt in a certain order to take on a greater challenge, the models/systems are expected to self-discover this curriculum. Viewed through these lenses it is easy to see how topology search methods are also often bundled into the conversation, as in and of itself topology search can be seen as a self-discovered curriculum (even with a fixed global objective).
</p>

<p>
  In the literature, methods such as POET have demonstrated that by evolving populations of agents and environments in concert, agents can be produced whose skill cannot be replicated without the exact sequence of environmental adaptation. PIC-Breeder showed that topology search coupled with objective drift led to robust internal representations unwittingly selecting for parameter/architectural evolvability. <a href="https://arxiv.org/pdf/2012.04322" target="_blank" rel="noopener noreferrer">Quality-Diversity</a> generally has demonstrated the utility of diverse phenotypic exploration as essential for optimal policy selection, but also transferability. All these methods implicitly or explicitly change the reward landscape, change objectives, use local competition and preserve utile novelty.
</p>

<hr>

<h2>Necessity for Stepping Stones</h2>
<img src="posts/curriculum-is-key/images/poet-main.png" alt="POET main setup" style="display:block; margin:20px auto; max-width:100%; height:auto;">
<p>
  One of the most prominent pieces of the open-endedness literature is POET. In which, it is shown that specific curricula can create agents that are otherwise unobtainable even under equivalent compute.
</p>

<p>
  POET evolves pairs of agents along with their environments simultaneously. The experiment begins with a single agent-environment pair. An agent consists of a bipedal walker and an environment consists of a 2D terrain that it must traverse. The initial environment is extremely simple, likewise, the initial agent is extremely dumb. It is assumed however, that at some point, the dumb agent will be able to achieve some level of competence in this simple environment. At which point, the environment will mutate. Crucially, the mutation is not random, it is first tested for learnability and novelty. In other words, can the agent make some progress in this environment (or is it impossible?) and is this environment different to other environments we have seen before? If both conditions are satisfied, a new agent-environment pair is spawned.
</p>

<p>
  The new pair carries with it the agent from the progenitor pair, so it is not starting from scratch. This new pair, and the old one, can continuously spawn new environments and pairs, creating a branching search through the space of agents and environments. The environments, satisfying the novelty and learnability criterion, ensure that agents trained on them will learn a new skill. The final piece of the POET puzzle is the transition phases. During a transition phase, agents can compete with other agents by testing on the incumbents' environments. If the foreign agent is better, it can displace it as the agent existing in that pair and training in that environment. This actually occurs often. The transfer phases are very important, because they serve as a task switching mechanism that does not require achieving competence on the current task. It may be the case that the current task is too difficult to be solved, but in the process, the agent discovers a much more efficient solution to a different task. By allowing transfer, this information is not lost. In fact the authors emphasise that the performance of POET is much reduced without transfer.
</p>

<img src="posts/curriculum-is-key/images/poet-results.png" alt="POET results" style="display:block; margin:20px auto; max-width:100%; height:auto;">

<p>
  Instead of focusing on the key implementation details, like how novelty and learnability are defined, it is more instructive to focus on the abstract takeaways and results. Critically, no agent trained directly or via linear curriculum on the end-stage complex environments were able to solve them. This means that the winding path taken by the agent that did solve a given challenge, was essential. It also, perhaps surprisingly, means that task switching does not necessarily mean loss of knowledge. If, from the optimisation's point of view, the agent's weights at the start of training on a new environment were irrelevant, then directly training on the new environments, without curriculum, should be solvable. Therefore, the weights must have carried valuable information from past experience. From a RL perspective, we can view the past experience as a form of pretraining that makes rewardable behaviour more likely.
</p>

<p>
  From POET we should abstract that task switching is essential as well as finding new tasks that are solvable. However, another key point is the importance of local competition and focus on instructive novelty. In POET, local competition emerges in the transfer phase. We can then reframe POET as a form of ‘genetic’ optimisation with local competition. Instead of many members of a population competing globally for a single unified goal, the population competes on many different goals. To persist, one needs only be the best on a single goal. This is analogous to speciation. It means that diverse behaviours are preserved and allows for specialisation of the agents for different challenges. These aspects are essential for building robust systems as it mirrors the quasi-discretisation of ideas needed for later recombination when facing new challenges.
</p>

<p>
  The notion of local competition with phenotypic diversity preservation is a recurring theme.
</p>

<h3>The Recipe - Summary</h3>
<ol>
  <li>Generate solvable novelty - evolve/find the niches.</li>
  <li>Preserve diversity with niches.</li>
  <li>Local competition within niche (transfer).</li>
</ol>

<hr>

<h2>Curriculum Produces Robustness</h2>
<p>
  Now we have seen that curriculum is essential for solving certain challenges that are otherwise unsolvable. Can we really be so sure however that the internal representations produced by these systems are robust, both at an individual agent level and at a meta population level?
</p>

<p>
  ‘The Fractured Entangled Representation Hypothesis’ (FERH) interrogates this question indirectly. In this paper the authors analyse images produced by Picbreeder.
</p>

<p>
  Picbreeder is an open-ended experiment in which users select images they like the look of iteratively. Under the hood, each image is represented by a CPPN (compositional pattern producing network). CPPNs are evolved using NEAT, a topology search algorithm. Every time the user clicks on images they find appealing (by whatever instantaneous metric they desire), the networks producing those images are bred. This in turn produces more images and the process goes on. After a few iterations the networks can produce interesting and recognisable shapes.
</p>
<img src="posts/curriculum-is-key/images/skull.png" alt="Picbreeder skull image" style="display:block; margin:20px auto; max-width:100%; height:auto;">
<p>
  The Picbreeder process followed those same underlying principles as POET. The users did not have an over-arching goal. This meant that every round of selection was a local competition in the direction of the user's interest at that moment. The user might see some aspect that has emerged suddenly, and completely change the course of the optimisation.
</p>

<p>
  Now, in the FERH paper, the authors trained another network by backpropagation to reproduce the above image. Its sole objective was the immediate reconstruction of this image. It was able to create an identical image. The major difference however was only revealed upon weight perturbations. Weight perturbations are a reasonable test of robustness because under new challenges, one expects robust representations to still be useful, just requiring a small amount of reconfiguration. The image produced by Picbreeder was very reasonable under different weight changes.
</p>
<img src="posts/curriculum-is-key/images/skull-good-perturbations.png" alt="Good perturbations in Picbreeder" style="display:block; margin:20px auto; max-width:100%; height:auto;">
<p>
  Different weights were clearly mixing different ideas that had been procured along the way. Another way of viewing this is as there being an easily configurable design space. On the other hand, the network trained directly to reconstruct the image had a completely uninterpretable design space. Different features of the output space were ‘entangled’ in seemingly meaningless ways.
</p>
<img src="posts/curriculum-is-key/images/skull-bad-perturbations.png" alt="Bad perturbations in direct reconstruction" style="display:block; margin:20px auto; max-width:100%; height:auto;">
<p>
  This evidence directly points to the fact that even if a curriculum is not required to achieve the goal (as it's not often when the objectives are differentiable), the lack of curriculum has a devastating effect. It reiterates the multiplication extrapolation. Without having first learned how to produce eyes, then a mouth then a head as separate building blocks, these concepts simply do not exist. Thus to expect this model to provide a useful starting point for future creative recombination is futile.
</p>

<p>
  If small parameter changes correspond to coherent changes in behaviour, then new tasks can be solved by small, structured reconfiguration rather than wholesale relearning. This is the mechanism by which robustness supports OOD creativity.
</p>

<hr>

<h2>Niches as Local Reward Basins</h2>
<p>
  We can view curriculum entirely through the lens of finding different niches. A niche can be thought of as a local reward basin. Again, this ties back to desparsifying the reward mechanism by finding local solvable instantiations.
</p>

<p>
  This is shown in <a href="https://docnum.univ-lorraine.fr/public/DDOC_T_2020_0087_GAIER.pdf#page=108.32" target="_blank" rel="noopener noreferrer">Accelerating Evolutionary Design</a>[...]. In this thesis, the author re-attempts the reconstruction challenge on the skull image above. However, instead of using backpropagation, they use NEAT. NEAT is a much weaker optimisation tool compared to backpropagation for reconstruction tasks. This is due to the fact NEAT is an evolutionary method and hence does not receive gradients that directly guide to minimising the reconstruction loss. The author compares using NEAT with MAP-Elites against NEAT with a direct reconstruction objective.
</p>

<p>
  MAP-Elites is a member of a family of methods called Quality-Diversity. The aim of a Quality-Diversity algorithm is not to solve any particular objective. It is instead, to create many local competitions in the phenotypic output space allowed for by the environment. For example, in the case of a maze solving robot task.
</p>

<p>
  Consider the following maze:
</p>
<img src="posts/curriculum-is-key/images/maze1.png" alt="Maze with traps and goal" style="display:block; margin:20px auto; max-width:100%; height:auto;">

<p>
  If one only optimised based on the distance from the end point, it would be so easy to get stuck in the various traps. In fact, it is very unlikely that the robot would be able to learn to escape them. MAP-Elites recognises this and so, in keeping with the common theme, instead creates pockets of local competition.
</p>
<img src="posts/curriculum-is-key/images/maze_cell.png" alt="Maze cells for local competition" style="display:block; margin:20px auto; max-width:100%; height:auto;">

<p>
  The maze space is divided into cells. Now, instead of evolving agents based on who can get to the end point, the agents are allowed to evolve freely. Each agent is given a phenotypic description (whichever cell it ends up in) and a fitness (how long it took to get there). Agents only compete with other agents in their cell based on the fitness metric. By not focusing on the global objective of reaching the end position, and instead only maximising the phenotypic coverage, it's easy to see how solutions finally emerge that reach the end goal!
</p>

<p>
  Unlike POET, the different niches are pre-defined, although variations on MAP-Elites have found ways around this. For example, one could just set a threshold endpoint distance within which solutions must compete based on fitness. Both POET and MAP-Elites rely on local competition (transfer events for POET). A superficial conceptual difference between the methods is that niches in POET are formed based on different challenges. In MAP-Elites however, niches are based on different behaviours within the remit of a challenge. This conceptual distinction is minor as in many cases, one can view the MAP-Elite phenotype as the POET environment. This is the case in the maze. The speed with which an agent reaches some destination (fitness/reward) is orthogonal information to the destination it reaches. Thus the POET equivalent would be that the MAP-Elites phenotype (destination cell) is the POET environment. Then, the MAP-Elites fitness (speed) is the POET reward within that environment.
</p>

<p>
  Linking back to the reconstruction experiment with NEAT. The MAP-Elites method defined niches based on similarity of images produced. This creates a large phenotypic space (an image is worth a thousand words). The local competition used was based on standard reconstruction loss with the target image.
  <img src="posts/curriculum-is-key/images/skull-aggregate.png" alt="Aggregate skull from MAP-Elites solutions" style="display:block; margin:20px auto; max-width:100%; height:auto;">
  
  The results are striking yet expected. Local competition, by retaining initially suboptimal solutions, allows for much more optimal solutions to occur in future. What is also shown here however, is that the mean image (average of solutions found by MAP-Elites) is much closer to the real image than any individual. This makes sense given that the individuals are now specialised species solving particular niches. The machinery required to extract a particular reward signal from the original image, may be totally different to that required to extract reward from some other part. This interesting tension highlights a fact that, local competition systems may in aggregate approximate predefined objectives, however it is very difficult for one solution to rise and surpass all the rest in every niche.
</p>

<p>
  In theory, a local competition system should eventually find a generalist solution that slowly spreads occupying more and more niches, however I am yet to observe this in the literature of these methods.
</p>

<hr>

<h2>Aggregate Intelligence From Niche Preservation</h2>
<p>
  As highlighted at the end of the last section, with any local competition system, it is difficult to obtain a single solution that solves all parts of the reward function. One need only look toward natural evolution and see that there is not a single species on earth that occupies every niche in the food chain, all collecting reward (continuous existence) from the universe. Instead there are many different morphologies. It is not clear that some reward sources can be obtained without limiting ones ability to collect reward from another source. In aggregate however, all reward possible is being collected (as much existence as can happen).
</p>

<p>
  This phenomenon may also be true for distributions we aim to model. In fact, we know it is the case because architectures that model tabular data well, may not model well, or be topologically incapable of modelling video data. It is only in aggregate that both distributions are modelled well, representing different species (models) and niches (distributions).
</p>

<p>
  Thus, although local competition creates robust and intelligent systems, and likely robust and intelligent agents, the population of agents as a whole is more capable than any individual. The closest exception to this rule in nature is humanity. Humanity possesses the most powerful design space of all creatures and the most generalist platform for extracting reward from almost any niche. Humans can outcompete squirrels for nuts, sharks for fish, viruses for bacteria, and it goes on and on.
</p>

<p>
  To bring things back to curriculum. If curriculum engines work by preserving niches, they may naturally produce population level factorisation. This raises the question, is generality the property of individuals or of a population?
</p>
